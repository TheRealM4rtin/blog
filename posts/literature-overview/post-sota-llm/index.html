<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>LLMs Compression | Literature Overview | TheRealMartin&#39;s Blog</title>
<meta name="keywords" content="paper, state-of-the-art, LLM">
<meta name="description" content="I&rsquo;m currently working on a research project on LLMs Compression. Making these models smaller and more efficient. This includes techniques like Pruning, Quantization, and Distillation.
Our work primarily explores three categories of LLM compression techniques: Quantization, knowledge Distillation, and Pruning. Each of these techniques offers a unique approach to reducing the size and computational demands of LLMs.
Quantization reduces the number of bits required to represent each weight in the model, thus decreasing its overall size.">
<meta name="author" content="">
<link rel="canonical" href="https://therealm4rtin.github.io/blog/posts/literature-overview/post-sota-llm/">
<link crossorigin="anonymous" href="/blog/assets/css/stylesheet.e087fd1dc76e73a35ae6d7028ddc1ba41e0131e7f9b3a6e2d019a208e6d6c4b5.css" integrity="sha256-4If9Hcduc6Na5tcCjdwbpB4BMef5s6bi0BmiCObWxLU=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/blog/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://therealm4rtin.github.io/blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://therealm4rtin.github.io/blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://therealm4rtin.github.io/blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://therealm4rtin.github.io/blog/apple-touch-icon.png">
<link rel="mask-icon" href="https://therealm4rtin.github.io/blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="LLMs Compression | Literature Overview" />
<meta property="og:description" content="I&rsquo;m currently working on a research project on LLMs Compression. Making these models smaller and more efficient. This includes techniques like Pruning, Quantization, and Distillation.
Our work primarily explores three categories of LLM compression techniques: Quantization, knowledge Distillation, and Pruning. Each of these techniques offers a unique approach to reducing the size and computational demands of LLMs.
Quantization reduces the number of bits required to represent each weight in the model, thus decreasing its overall size." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://therealm4rtin.github.io/blog/posts/literature-overview/post-sota-llm/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-25T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-01-25T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="LLMs Compression | Literature Overview"/>
<meta name="twitter:description" content="I&rsquo;m currently working on a research project on LLMs Compression. Making these models smaller and more efficient. This includes techniques like Pruning, Quantization, and Distillation.
Our work primarily explores three categories of LLM compression techniques: Quantization, knowledge Distillation, and Pruning. Each of these techniques offers a unique approach to reducing the size and computational demands of LLMs.
Quantization reduces the number of bits required to represent each weight in the model, thus decreasing its overall size."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://therealm4rtin.github.io/blog/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "LLMs Compression | Literature Overview",
      "item": "https://therealm4rtin.github.io/blog/posts/literature-overview/post-sota-llm/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "LLMs Compression | Literature Overview",
  "name": "LLMs Compression | Literature Overview",
  "description": "I\u0026rsquo;m currently working on a research project on LLMs Compression. Making these models smaller and more efficient. This includes techniques like Pruning, Quantization, and Distillation.\nOur work primarily explores three categories of LLM compression techniques: Quantization, knowledge Distillation, and Pruning. Each of these techniques offers a unique approach to reducing the size and computational demands of LLMs.\nQuantization reduces the number of bits required to represent each weight in the model, thus decreasing its overall size.",
  "keywords": [
    "paper", "state-of-the-art", "LLM"
  ],
  "articleBody": "I’m currently working on a research project on LLMs Compression. Making these models smaller and more efficient. This includes techniques like Pruning, Quantization, and Distillation.\nOur work primarily explores three categories of LLM compression techniques: Quantization, knowledge Distillation, and Pruning. Each of these techniques offers a unique approach to reducing the size and computational demands of LLMs.\nQuantization reduces the number of bits required to represent each weight in the model, thus decreasing its overall size. Knowledge Distillation effectively condensing the knowledge by training a smaller model (student) to replicate the performance of a larger one (teacher). Pruning involves removing less important parts of the model to\nmake it more efficient without significant loss in performance. During our research, we gathered over 150 research papers related to state-of-the-art LLMs Compression methods and Optimization. I think this collection is pretty valuable. So here’s this massive pile of research for you.\nThe paper will be published mid-2024.\nNote that if you see a green check emoji ✅ next to a paper on the Notion page, it means there’s a brief report available for that paper right there on the page.\nRight now, the collection is organized as a Notion webpage that I’ve made accessible. I’m still considering other platforms like Zotero or GitHub to host this library, but I haven’t settled on one yet. If you have any suggestions or preferences, let me know.\nSome themes covered Quantization Pruning Distillation Low-Rank Factorization Compression Finetuning Hyperparameters Encoding Prompt Benchmarks Open Source Models Agents Memory https://therealmartin.notion.site/LLM-Compression-A-state-of-the-art-6a920ba022c54f0ab4e47b0654e7b738?pvs=4\n",
  "wordCount" : "252",
  "inLanguage": "en",
  "datePublished": "2024-01-25T00:00:00Z",
  "dateModified": "2024-01-25T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://therealm4rtin.github.io/blog/posts/literature-overview/post-sota-llm/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "TheRealMartin's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://therealm4rtin.github.io/blog/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://therealm4rtin.github.io/blog/" accesskey="h" title="TheRealMartin&#39;s Blog (Alt + H)">
                <img src="https://therealm4rtin.github.io/blog/images/favicon.png" alt="" aria-label="logo"
                    height="30">TheRealMartin&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://therealm4rtin.github.io/blog/archives/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://therealm4rtin.github.io/blog/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://therealm4rtin.github.io/blog/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://therealm4rtin.github.io/blog/about/" title="About Me">
                    <span>About Me</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://therealm4rtin.github.io/blog/">Home</a>&nbsp;»&nbsp;<a href="https://therealm4rtin.github.io/blog/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      LLMs Compression | Literature Overview
    </h1>
    <div class="post-meta"><span title='2024-01-25 00:00:00 +0000 UTC'>January 25, 2024</span>&nbsp;·&nbsp;2 min

</div>
  </header> 
  <div class="post-content"><p>I&rsquo;m currently working on a research project on LLMs Compression. Making these models smaller and more efficient. This includes techniques like Pruning, Quantization, and Distillation.</p>
<p>Our work primarily explores three categories of LLM compression techniques: <strong>Quantization</strong>, <strong>knowledge Distillation</strong>, and <strong>Pruning</strong>. Each of these techniques offers a unique approach to reducing the size and computational demands of LLMs.</p>
<ul>
<li>Quantization reduces the number of bits required to represent each weight in the model, thus decreasing its overall size.</li>
<li>Knowledge Distillation effectively condensing the knowledge by training a smaller model (student) to replicate the performance of a larger one (teacher).</li>
<li>Pruning involves removing less important parts of the model to<br>
make it more efficient without significant loss in performance.</li>
</ul>
<p>During our research, we gathered over 150 research papers related to state-of-the-art LLMs Compression methods and Optimization. I think this collection is pretty valuable. So here&rsquo;s this massive pile of research for you.</p>
<p>The paper will be published mid-2024.</p>
<hr>
<p>Note that if you see a green check emoji ✅ next to a paper on the Notion page, it means there&rsquo;s a brief report available for that paper right there on the page.</p>
<hr>
<p>Right now, the collection is organized as a Notion webpage that I&rsquo;ve made accessible. I&rsquo;m still considering other platforms like Zotero or GitHub to host this library, but I haven&rsquo;t settled on one yet. If you have any suggestions or preferences, <em>let me know</em>.</p>
<hr>
<table>
<thead>
<tr>
<th>Some themes covered</th>
</tr>
</thead>
<tbody>
<tr>
<td>Quantization</td>
</tr>
<tr>
<td>Pruning</td>
</tr>
<tr>
<td>Distillation</td>
</tr>
<tr>
<td>Low-Rank Factorization</td>
</tr>
<tr>
<td>Compression</td>
</tr>
<tr>
<td>Finetuning</td>
</tr>
<tr>
<td>Hyperparameters</td>
</tr>
<tr>
<td>Encoding</td>
</tr>
<tr>
<td>Prompt</td>
</tr>
<tr>
<td>Benchmarks</td>
</tr>
<tr>
<td>Open Source Models</td>
</tr>
<tr>
<td>Agents</td>
</tr>
<tr>
<td>Memory</td>
</tr>
</tbody>
</table>
<p><a href="https://therealmartin.notion.site/LLM-Compression-A-state-of-the-art-6a920ba022c54f0ab4e47b0654e7b738?pvs=4">https://therealmartin.notion.site/LLM-Compression-A-state-of-the-art-6a920ba022c54f0ab4e47b0654e7b738?pvs=4</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://therealm4rtin.github.io/blog/tags/paper/">paper</a></li>
      <li><a href="https://therealm4rtin.github.io/blog/tags/state-of-the-art/">state-of-the-art</a></li>
      <li><a href="https://therealm4rtin.github.io/blog/tags/llm/">LLM</a></li>
    </ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://therealm4rtin.github.io/blog/">TheRealMartin&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
